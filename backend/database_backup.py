#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º–∏ –∫–æ–ø–∏—è–º–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö MongoDB
–ü–æ–∑–≤–æ–ª—è–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤/–∏–∑ JSON —Ñ–∞–π–ª–æ–≤
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from motor.motor_asyncio import AsyncIOMotorClient
from dotenv import load_dotenv
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ MongoDB
MONGO_URL = os.environ.get('MONGO_URL', 'mongodb://localhost:27017')
DB_NAME = os.environ.get('DB_NAME', 'test_database')

# –ü–∞–ø–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
BACKUP_DIR = ROOT_DIR / 'data'
BACKUP_DIR.mkdir(exist_ok=True)

# –ö–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
COLLECTIONS = ['products', 'projects', 'orders', 'feedback']

class DatabaseBackup:
    def __init__(self):
        self.client = AsyncIOMotorClient(MONGO_URL)
        self.db = self.client[DB_NAME]

    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î"""
        self.client.close()

    async def export_collection(self, collection_name: str) -> list:
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            collection = self.db[collection_name]
            documents = await collection.find().to_list(None)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ObjectId –∏ datetime –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            for doc in documents:
                if '_id' in doc:
                    del doc['_id']  # –£–¥–∞–ª—è–µ–º ObjectId, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à uuid –≤ –ø–æ–ª–µ id
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º datetime –æ–±—ä–µ–∫—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏
                for key, value in doc.items():
                    if hasattr(value, 'isoformat'):
                        doc[key] = value.isoformat()
            
            logger.info(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'")
            return documents
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}': {e}")
            return []

    async def import_collection(self, collection_name: str, documents: list) -> bool:
        """–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
        try:
            if not documents:
                logger.info(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é '{collection_name}'")
                return True

            collection = self.db[collection_name]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ datetime –æ–±—Ä–∞—Ç–Ω–æ –≤ datetime –æ–±—ä–µ–∫—Ç—ã
            for doc in documents:
                if 'created_at' in doc and isinstance(doc['created_at'], str):
                    try:
                        doc['created_at'] = datetime.fromisoformat(doc['created_at'].replace('Z', '+00:00'))
                    except:
                        doc['created_at'] = datetime.utcnow()
            
            # –û—á–∏—â–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
            await collection.delete_many({})
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            if documents:
                await collection.insert_many(documents)
            
            logger.info(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é '{collection_name}'")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}': {e}")
            return False

    async def create_backup(self) -> bool:
        """–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø –≤—Å–µ—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_info = {
                'timestamp': datetime.now().isoformat(),
                'collections': {}
            }

            logger.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏...")

            for collection_name in COLLECTIONS:
                documents = await self.export_collection(collection_name)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                backup_file = BACKUP_DIR / f"{collection_name}.json"
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump(documents, f, ensure_ascii=False, indent=2)
                
                backup_info['collections'][collection_name] = len(documents)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—ç–∫–∞–ø–µ
            info_file = BACKUP_DIR / "backup_info.json"
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(backup_info, f, ensure_ascii=False, indent=2)

            logger.info(f"–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {BACKUP_DIR}")
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return False

    async def restore_backup(self) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        try:
            logger.info("–ù–∞—á–∏–Ω–∞–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏...")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –±—ç–∫–∞–ø–µ
            info_file = BACKUP_DIR / "backup_info.json"
            if info_file.exists():
                with open(info_file, 'r', encoding='utf-8') as f:
                    backup_info = json.load(f)
                logger.info(f"–ù–∞–π–¥–µ–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –æ—Ç {backup_info['timestamp']}")

            success_count = 0
            for collection_name in COLLECTIONS:
                backup_file = BACKUP_DIR / f"{collection_name}.json"
                
                if backup_file.exists():
                    with open(backup_file, 'r', encoding='utf-8') as f:
                        documents = json.load(f)
                    
                    if await self.import_collection(collection_name, documents):
                        success_count += 1
                else:
                    logger.warning(f"–§–∞–π–ª —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {backup_file}")

            if success_count == len(COLLECTIONS):
                logger.info("–í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏!")
                return True
            else:
                logger.warning(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {success_count} –∏–∑ {len(COLLECTIONS)} –∫–æ–ª–ª–µ–∫—Ü–∏–π")
                return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏: {e}")
            return False

    async def get_database_status(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            status = {}
            total_documents = 0
            
            for collection_name in COLLECTIONS:
                collection = self.db[collection_name]
                count = await collection.count_documents({})
                status[collection_name] = count
                total_documents += count
            
            status['total'] = total_documents
            status['has_data'] = total_documents > 0
            
            return status
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –ë–î: {e}")
            return {}

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    if len(sys.argv) < 2:
        print("Usage: python database_backup.py [export|import|status]")
        print("  export - —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é")
        print("  import - –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
        print("  status - –ø–æ–∫–∞–∑–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        return

    command = sys.argv[1].lower()
    backup = DatabaseBackup()

    try:
        if command == 'export':
            success = await backup.create_backup()
            if success:
                print("‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            else:
                print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
                
        elif command == 'import':
            success = await backup.restore_backup()
            if success:
                print("‚úÖ –î–∞–Ω–Ω—ã–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            else:
                print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
                
        elif command == 'status':
            status = await backup.get_database_status()
            print("\nüìä –°–æ—Å—Ç–æ—è–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
            print("-" * 30)
            for collection, count in status.items():
                if collection != 'total' and collection != 'has_data':
                    print(f"{collection}: {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            print("-" * 30)
            print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {status.get('total', 0)}")
            print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö {'–∑–∞–ø–æ–ª–Ω–µ–Ω–∞' if status.get('has_data', False) else '–ø—É—Å—Ç–∞'}")
            
        else:
            print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {command}")

    finally:
        await backup.close()

if __name__ == "__main__":
    asyncio.run(main())